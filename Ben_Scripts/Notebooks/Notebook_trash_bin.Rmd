---
title: "Notebook trash bin"
output: html_notebook
---

Next, I want to obtain the latency between the time the box was introduced into the pond and the moment each individual fully explored it. I create the *lat.expl* function, which has, as an:

- Inout: The reads corresponding to antenna changes for all individuals (data frame). Details in the chunk just above.
- Output: The first box cross for all individuals (data frame). A column is also computing how long since the box has been introduced the individuals have taken to enter the box.
    
    
```{r, message = FALSE}
    
    
# 1. I create the 'lat.expl' function for 'Latency to explore'.
    # From the cleaned data frame, it outputs all the individual full crossings.
    lat.expl <- function(df, pattern1, pattern2, initial_time){
    
      
      
  ## 2. IDENTIFY WHEN INDIVIDUALS CROSS THE BOX ENTIRELY
  # I stole the next piece of code from someone way smarter than me (R Stack Overflow 41130912).
  # First, I keep reads when individuals go through the box the following way: 1 -> 2 -> 3 -> 4
    len_pattern = 4
    df_abcd <- df %>% arrange(id, time) %>% group_by(id) %>%
    # check multiple lags condition
    mutate(ab = Reduce("&", Map("==", shift(antenna, n = 0:(len_pattern - 1), type = "lead"), pattern1)),
    g = cumsum(ab)) %>%
    # use reduce or to subset sequence rows having the same length as the pattern
    filter(Reduce("|", shift(ab, n = 0:(len_pattern - 1), type = "lag"))) %>%
    # make unique names
    group_by(g, add = TRUE) %>% mutate(antenna = paste(antenna, 1:n(), sep = "_")) %>%
    # pivoting the table to wide format
    select(-ab) %>% spread(antenna, time)



  # Second, I keep reads when individuals go through the box the other way around: 4 -> 3 -> 2 -> 1
    df_dcba <- df %>% arrange(id, time) %>% group_by(id) %>%
    # check multiple lags condition
    mutate(ab = Reduce("&", Map("==", shift(antenna, n = 0:(len_pattern - 1), type = "lead"), pattern2)),
    g = cumsum(ab)) %>%
    # use reduce to subset sequence rows having the same length as the pattern
    filter(Reduce("|", shift(ab, n = 0:(len_pattern - 1), type = "lag"))) %>%
    # make unique names
    group_by(g, add = TRUE) %>% mutate(antenna = paste(antenna, 1:n(), sep = "_")) %>%
    # pivoting the table to wide format
    select(-ab) %>% spread(antenna, time)


    
    
  # I rename the columns of the two dataframes I created
  names(df_abcd) <- c("id", "time_of_day", "Pond", "Treatment_seq", "g", 
                      "Ant1", "Ant2", "Ant3", "Ant4")
  names(df_dcba) <- c("id", "time_of_day", "Pond", "Treatment_seq", "g", 
                      "Ant1", "Ant2", "Ant3", "Ant4")

  
  # I obtain a dataframe in which each row represents one individual full crossing
  df3 <- rbind(df_abcd, df_dcba)

  
  # I keep individuals with the smallest 'arrival' (i.e. Ant2) value.
  df3 <- df3 %>%
    group_by(id) %>%
    slice(which.min(Ant2))


  ## 3. CALCULATE LATENCY TIME
  # I add a new column with the time to cross the box since the start of the test
  df3 <- mutate(df3, time_since_start = difftime(Ant2, initial_time, units='mins'))
  df3$time_since_start <- as.numeric(df3$time_since_start)




  return(df3)
}

```


I run my function for each half-day, as the starting time will differ. Then, I merge them together.

```{r, message = FALSE}


# I run my functions for the morning and the afternoon
  EB_Lat_Morning <- lat.expl(subset(EB_Changes, time_of_day == "Morning"), 
                             p1.4, p4.1, start_morning)
  EB_Lat_Afternoon <- lat.expl(subset(EB_Changes, time_of_day == "Afternoon"), 
                               p1.4, p4.1, start_afternoon)

  

# I obtain my final dataset with the first crossing sequence for every
# individual and at what time it happened
  EB_Lat <- rbind(EB_Lat_Morning, EB_Lat_Afternoon)
  
  
```







---



```{r, message = FALSE}
shoaling.index <- function(clean_df, df_variables){

  
  
# I split my data frame into a list of dataframes (one object per individual)
  # PROBLEM HERE, ANTENNA NÂ°1 IN DIFF PONDS
  clean_df_2 <- split(clean_df, f = clean_df$antenna)

# I define a list
  accompanied_reads <- list()
  
    # For each antenna...
    for (i in 1:length(clean_df_2)){
     
      # I subset all the time points for which more than 1 individuals were read at one antenna
      accompanied_reads[[i]] <-  clean_df_2[[i]] %>% group_by(time) %>% filter(n() > 1)
  
      # I count the number of accompanied reads per individual
      accompanied_reads[[i]] <- accompanied_reads[[i]] %>% group_by(id) %>% add_tally()
      # I remove duplicated rows
      accompanied_reads[[i]] <- accompanied_reads[[i]][!duplicated(accompanied_reads[[i]][,c('id')]),]
    }
  
  
  # I bind the rows of the list of dataframes
    accompanied_reads <- bind_rows(accompanied_reads)
  
    # I keep the total number of accompanied reads in all antennas
    accompanied_reads <- accompanied_reads %>%
      group_by(id) %>%
      mutate(tot_acc_reads = sum(n))

    
    
  # I remove the 'n' column, useless now
    accompanied_reads <- accompanied_reads[,- c(7)]
  # I remove duplicated rows
    accompanied_reads <- accompanied_reads[!duplicated(accompanied_reads[,c('id')]),]
  
  # Now, I want to take into account the total number of reads of each individual as well
    clean_df <- clean_df %>% group_by(id) %>% add_tally()
    clean_df <- clean_df[!duplicated(clean_df[,c('id')]),]
    clean_df <- merge(EB_variables, clean_df[c("id", "n")], by = "id", all = T)
    clean_df[is.na(clean_df)] <- 0
    
  # I add them to the data frame with the accompanied reads
    accompanied_reads <- merge(clean_df[c("id", "Pond", "time_of_day", "Treatment_seq", "n")], 
                               accompanied_reads[c("id", "tot_acc_reads")], by = "id", all = T) 
    names(accompanied_reads)[5] <- "tot_reads"
    accompanied_reads[is.na(accompanied_reads)] <- 0
    accompanied_reads$shoaling <- accompanied_reads$tot_acc_reads/accompanied_reads$tot_reads
    return(accompanied_reads)
    
  } # end of function

```
